BOX_IMAGE = "ubuntu/focal64"
WORKER_COUNT = 1
KUBE_VERSION = "1.25.0"

#First three octets of the desired host network
HOST_NET = "10.123.0"

CTRL_PLANE_IP = "10.123.0.100"
POD_NETWORK_CIDR = "10.244.0.0/16"

Vagrant.configure("2") do |config|

  config.ssh.insert_key = false

  config.vm.synced_folder "/mnt/data/kubernetes", "/mnt/data/kubernetes"

  config.vm.provider "virtualbox" do |v|
    v.memory = 4096
    v.cpus = 2
  end

  #Run the common script on all VMs (ctrlplane + workers)
  config.vm.provision "shell", path: "scripts/common.sh", 
    env: {"KUBE_VERSION" => KUBE_VERSION, "HOST_NET" => HOST_NET}

  #Create the control plane instance
  config.vm.define "ctrlplane" do |ctrlplane|
    ctrlplane.vm.box = BOX_IMAGE
    ctrlplane.vm.hostname = "ctrlplane"

    #Host-only network to access control plane node from dell precision workstation 
    ctrlplane.vm.network "private_network", ip: CTRL_PLANE_IP, netmask: "255.255.0.0"    

    ctrlplane.vm.provision "shell", path: "scripts/ctrlplane.sh", 
      env: {"CTRL_PLANE_IP" => CTRL_PLANE_IP, "POD_NETWORK_CIDR" => POD_NETWORK_CIDR}
    
    #Run the scripts/local-kubectl.sh configure script after the controlplane has been created
    ctrlplane.trigger.after [:up] do |trigger|
      trigger.info = "Running scripts/local-kubectl.sh locally."
      trigger.run = {path: "scripts/local-kubectl.sh"}
    end
  end
  
  #worker nodes
  (1..WORKER_COUNT).each do |i|
    config.vm.define "node#{i}" do |worker|
      worker.vm.box = BOX_IMAGE
      worker.vm.hostname = "node#{i}"

      WORKER_IP = "10.123.0.#{i + 100}"

      #Host-only network to access worker nodes from dell precision workstation
      worker.vm.network "private_network", ip: WORKER_IP, netmask: "255.255.0.0"

      worker.vm.provision "shell", path: "scripts/worker.sh", 
        env: {"CTRL_PLANE_IP" => CTRL_PLANE_IP, "POD_NETWORK_CIDR" => POD_NETWORK_CIDR, "WORKER_IP" => WORKER_IP}
    end 
  end
end
